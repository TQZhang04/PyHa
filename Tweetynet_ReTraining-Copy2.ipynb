{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9ee970",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from PyHa.statistics import *\n",
    "from PyHa.IsoAutio import *\n",
    "from PyHa.visualizations import *\n",
    "from PyHa.annotation_post_processing import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0361ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./mixed_bird/025_Mixed_Bird_Outputs_Train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ef9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyHa.tweetynet_package.tweetynet.Load_data_functions import compute_features, predictions_to_kaleidoscope\n",
    "from PyHa.microfaune_package.microfaune import audio\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795746a7",
   "metadata": {},
   "source": [
    "# PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad9b236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.kaledoscope_dataset at 0x1c8e704ac08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "class kaledoscope_dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file,filepath, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.manual_df = pd.read_csv(csv_file)\n",
    "        self.manual_df[\"FOLDER\"] = self.manual_df[\"IN FILE\"].apply(lambda x: filepath)\n",
    "        self.audio_files = self.manual_df[[\"FOLDER\",\"IN FILE\"]].drop_duplicates().reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.manual_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: FIX MAGIC NUMBERS\n",
    "        normalized_sample_rate=44100\n",
    "\n",
    "        audio_df = self.audio_files.iloc[idx]\n",
    "        \n",
    "        audio_dif = audio_df[\"FOLDER\"]\n",
    "        audio_file = audio_df[\"IN FILE\"]\n",
    "        try:\n",
    "            SAMPLE_RATE, SIGNAL = audio.load_wav(audio_dif + audio_file)\n",
    "        except BaseException as e:\n",
    "            #print(\"Failed to load\", audio_dif + audio_file)\n",
    "            #print(e)\n",
    "            return (-1,-1)\n",
    "        \n",
    "        try:\n",
    "            if SAMPLE_RATE != normalized_sample_rate:\n",
    "                rate_ratio = normalized_sample_rate / SAMPLE_RATE\n",
    "                SIGNAL = scipy_signal.resample(\n",
    "                    SIGNAL, int(len(SIGNAL) * rate_ratio))\n",
    "                SAMPLE_RATE = normalized_sample_rate\n",
    "        except:\n",
    "            print(\"Failed to Downsample\" + audio_file)\n",
    "            return (-1,-1)\n",
    "            \n",
    "        if len(SIGNAL.shape) == 2:\n",
    "            SIGNAL = SIGNAL.sum(axis=1) / 2\n",
    "        # detection\n",
    "        try:\n",
    "            tweetynet_features = compute_features([SIGNAL])\n",
    "        except:\n",
    "            print(\"Failed to compute features\" + audio_file)\n",
    "            return (-1,-1)\n",
    "        \n",
    "\n",
    "            \n",
    "        label_df = self.manual_df[(self.manual_df[\"FOLDER\"] == audio_df[\"FOLDER\"]) & (self.manual_df[\"IN FILE\"] == audio_df[\"IN FILE\"])]\n",
    "        return (tweetynet_features, label_df, audio_dif, audio_file, SIGNAL, SAMPLE_RATE)\n",
    "    \n",
    "trainloader = kaledoscope_dataset(\"mixed_bird_manual.csv\", path)\n",
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e887849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init detector\n",
    "device = torch.device('cpu')\n",
    "net_wrapper = TweetyNetModel(2, (1, 86, 86), 86, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae16845",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7ecf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: DEFINE TEST LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b7441d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IOU_Loss(automated_df, manual_df):\n",
    "    IoUMatrix = torch.tensor(clip_IoU(automated_df, manual_df));\n",
    "    return torch.mean(IoUMatrix)\n",
    "\n",
    "def convert_label_to_local_score(manual_df, size_of_local_sorce, start_time = 0):\n",
    "    duration_of_clip = manual_df.iloc[0][\"CLIP LENGTH\"]\n",
    "    seconds_per_index = duration_of_clip/size_of_local_sorce\n",
    "    local_score = np.zeros(size_of_local_sorce)\n",
    "    for i in range(size_of_local_sorce):\n",
    "        current_seconds = i * seconds_per_index + start_time\n",
    "        annotations_at_time = manual_df[(manual_df[\"OFFSET\"] <= current_seconds) & (manual_df[\"OFFSET\"] +manual_df[\"DURATION\"] >=  current_seconds)]\n",
    "        if (not annotations_at_time.empty):\n",
    "            local_score[i] = 1\n",
    "    \n",
    "    return torch.tensor(local_score).float()\n",
    "\n",
    "\n",
    "\n",
    "manual_df  = pd.read_csv(\"ScreamingPiha_Manual_Labels.csv\")\n",
    "convert_label_to_local_score(manual_df[manual_df[\"IN FILE\"] == \"ScreamingPiha5.wav\"], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2ed87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "net = net_wrapper.model\n",
    "print(list(net.parameters())[0].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1808, grad_fn=<NllLossBackward0>)\n",
      "[(1, 2)] loss: 0.430 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "[(1, 12)] loss: 0.087 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "[(1, 16)] loss: 0.076 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.7278, grad_fn=<NllLossBackward0>)\n",
      "[(1, 35)] loss: 0.188 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
      "[(1, 38)] loss: 0.177 None\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0954, grad_fn=<NllLossBackward0>)\n",
      "[(1, 39)] loss: 0.175 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(2.3931, grad_fn=<NllLossBackward0>)\n",
      "[(1, 60)] loss: 0.307 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.0450, grad_fn=<NllLossBackward0>)\n",
      "[(1, 73)] loss: 0.283 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.2984, grad_fn=<NllLossBackward0>)\n",
      "[(1, 90)] loss: 0.255 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
      "[(1, 104)] loss: 0.243 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "[(1, 114)] loss: 0.225 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "[(1, 118)] loss: 0.219 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1490, grad_fn=<NllLossBackward0>)\n",
      "[(1, 126)] loss: 0.208 None\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "[(1, 128)] loss: 0.205 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1425, grad_fn=<NllLossBackward0>)\n",
      "[(1, 136)] loss: 0.196 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "[(1, 142)] loss: 0.188 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(2.4368, grad_fn=<NllLossBackward0>)\n",
      "[(1, 168)] loss: 0.244 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
      "[(1, 173)] loss: 0.253 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.8479, grad_fn=<NllLossBackward0>)\n",
      "[(1, 189)] loss: 0.255 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.4309, grad_fn=<NllLossBackward0>)\n",
      "[(1, 208)] loss: 0.274 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.0857, grad_fn=<NllLossBackward0>)\n",
      "[(1, 229)] loss: 0.283 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0308, grad_fn=<NllLossBackward0>)\n",
      "[(1, 233)] loss: 0.279 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(4.7194, grad_fn=<NllLossBackward0>)\n",
      "[(1, 264)] loss: 0.429 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.1506, grad_fn=<NllLossBackward0>)\n",
      "[(1, 307)] loss: 0.455 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1357, grad_fn=<NllLossBackward0>)\n",
      "[(1, 318)] loss: 0.449 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(3.2851, grad_fn=<NllLossBackward0>)\n",
      "[(1, 348)] loss: 0.541 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "[(1, 351)] loss: 0.537 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.2372, grad_fn=<NllLossBackward0>)\n",
      "[(1, 362)] loss: 0.524 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(3.1865, grad_fn=<NllLossBackward0>)\n",
      "[(1, 396)] loss: 0.584 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.2166, grad_fn=<NllLossBackward0>)\n",
      "[(1, 421)] loss: 0.577 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(2.5673, grad_fn=<NllLossBackward0>)\n",
      "[(1, 443)] loss: 0.583 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(5.9631e-06, grad_fn=<NllLossBackward0>)\n",
      "[(1, 447)] loss: 0.579 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1291, grad_fn=<NllLossBackward0>)\n",
      "[(1, 455)] loss: 0.569 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.6168, grad_fn=<NllLossBackward0>)\n",
      "[(1, 479)] loss: 0.573 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "[(1, 486)] loss: 0.565 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.6441, grad_fn=<NllLossBackward0>)\n",
      "[(1, 509)] loss: 0.551 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1136, grad_fn=<NllLossBackward0>)\n",
      "[(1, 515)] loss: 0.546 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0417, grad_fn=<NllLossBackward0>)\n",
      "[(1, 524)] loss: 0.538 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.8305, grad_fn=<NllLossBackward0>)\n",
      "[(1, 552)] loss: 0.534 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.1914, grad_fn=<NllLossBackward0>)\n",
      "[(1, 564)] loss: 0.530 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "[(1, 571)] loss: 0.524 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.4547, grad_fn=<NllLossBackward0>)\n",
      "[(1, 585)] loss: 0.515 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "[(1, 595)] loss: 0.507 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.7166, grad_fn=<NllLossBackward0>)\n",
      "[(1, 608)] loss: 0.498 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(1.7371, grad_fn=<NllLossBackward0>)\n",
      "[(1, 630)] loss: 0.498 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "[(1, 651)] loss: 0.492 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0723, grad_fn=<NllLossBackward0>)\n",
      "[(1, 662)] loss: 0.484 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0254, grad_fn=<NllLossBackward0>)\n",
      "[(1, 665)] loss: 0.482 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(10.5328, grad_fn=<NllLossBackward0>)\n",
      "[(1, 729)] loss: 0.653 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "DONE ONE FILE\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "[(1, 739)] loss: 0.645 None\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "net = net_wrapper.model\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    mini_batch_count = 0\n",
    "    batch_count = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        try:\n",
    "            inputs, labels, audio_dif, audio_file, SIGNAL, SAMPLE_RATE = data\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        device = torch.device('cpu')\n",
    "        net = net_wrapper.model\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        batch_size=1\n",
    "        window_size=2\n",
    "        test_data_loader = DataLoader(inputs, batch_size=batch_size)\n",
    "        predictions = pd.DataFrame()\n",
    "        net_wrapper.model.eval()\n",
    "        local_score = torch.tensor([])\n",
    "        tmp_local_score = []\n",
    "        dataiter = iter(test_data_loader)\n",
    "        _, label, uid = dataiter.next()\n",
    "        time_bin = float(window_size)/label.shape[1]\n",
    "        st_time = np.array([time_bin*n for n in range(label.shape[1])])\n",
    "        count = []\n",
    "        \n",
    "        for i, data in enumerate(test_data_loader):\n",
    "                \n",
    "            #Run Model\n",
    "            sub_inputs, sub_labels, uids = data\n",
    "            sub_inputs = sub_inputs.clone().detach().requires_grad_(True)\n",
    "            sub_inputs, sub_labels = sub_inputs.to(device), sub_labels.to(device)\n",
    "            output = net_wrapper.model(sub_inputs, sub_inputs.shape[0], sub_inputs.shape[0])\n",
    "            \n",
    "            #Get labels for window\n",
    "            bins = st_time + (int(uids[0].split(\"_\")[0])*window_size)\n",
    "            label_for_output = convert_label_to_local_score(manual_df, len([x for x in output[0, 1, :]]), bins[0])\n",
    "            \n",
    "            #Set up output for correct batch * class matrix\n",
    "            output_for_loss = torch.transpose(output.clone()[0].clone(), 0, 1).clone().float()\n",
    "            \n",
    "            #Compute Loss\n",
    "            output = output_for_loss\n",
    "            label_array =label_for_output\n",
    "            label_array = label_array.long()\n",
    "            loss = criterion(output, label_array)\n",
    "            \n",
    "            #Backprop + Check for learning\n",
    "            state_a = net_wrapper.model.state_dict().__str__()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            state_b = net_wrapper.model.state_dict().__str__()\n",
    "            if state_a == state_b:\n",
    "                print(\"Network not updating.\")\n",
    "\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            batch_loss += loss.item()\n",
    "            mini_batch_count += 1\n",
    "            batch_count += 1\n",
    "            print(\"=======================\")\n",
    "\n",
    "        print(\"DONE ONE FILE\")\n",
    "        print(f'[{epoch + 1, mini_batch_count}] loss: {running_loss / mini_batch_count:.3f}')\n",
    "    print(f'[{epoch + 1, batch_count}] loss: {batch_loss / batch_count:.3f}')\n",
    "    batch_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), \"./test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae002d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n",
    "#correct = 0\n",
    "#total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "\n",
    "\n",
    "#isolation_parameters = {\n",
    "#     \"model\" : \"tweetynet\",\n",
    "#     \"tweety_output\": True,\n",
    "#    \"technique\" : \"steinberg\",\n",
    "#     \"threshold_type\" : \"median\",\n",
    "#     \"threshold_const\" : 2.0,\n",
    "#     \"threshold_min\" : 0.0,\n",
    "#     \"window_size\" : 2.0,\n",
    "#     \"chunk_size\" : 5.0\n",
    "#}\n",
    "#automated_df = generate_automated_labels(path,isolation_parameters, weight_path=\"./test.h5\");\n",
    "#display(automated_df)\n",
    "#manual_df = pd.read_csv(\"mixed_bird_manual.csv\")\n",
    "#statistics_df = automated_labeling_statistics(automated_df,manual_df,stats_type = \"general\");\n",
    "#statistics_df\n",
    "#global_dataset_statistics(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec195b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
